{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06a21413",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3c75bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/toshalimohapatra/Documents/Chatbot_Langchain/data/textfile.txt'}, page_content='Brains are highly fashionable. A very common belief is that the human mind and cognition lie in the head, within the confines of a spongy greyish organ called ‘the brain’ encased within skull and skin. While I was looking at that Thinker’s head, with my stomach protesting, I realised I had completely dismissed his body. I was obsessed with understanding his mind, and my mind via his brain, but I completely ignored the rest of him. Like the great majority of scientists and philosophers throughout history, I too was putting cognition into the head and forgetting about the body, treating it as something that got in the way of pure cerebral thought.\\n\\nBeing a philosopher hadn’t been my only dream.\\n\\nWhy are we so reluctant to consider the brain as just another part of the body?\\n\\nI’d decided to study philosophy after becoming a frustrated musician. My parents, God bless them, considered that singing opera and playing piano were cool ways to impress the visitors, but wouldn’t lead to a career. Now they regret their decision not to allow me to take a musical path. When visitors politely ask what their daughter is doing for a living and they reply: ‘She’s a philosopher,’ the visitors look puzzled as if needing an extra explanation: ‘Yes, but what exactly is she doing?’ My parents can’t say ‘she’s thinking’ because that would make them look silly, and they are extremely proud and reasonable folks. Now, if I were a musician, well, that would have been way simpler. Everyone gets what musicians do.\\n\\nThere is no doubt a modern fascination with the thinking brain as the fundamental basis of human cognition. But why? Is this the only entrance point that allows us to understand who we are and what human cognition is? Here I propose another angle. While neurons are indeed fascinating, their complex activity is only part of the story of human cognition.\\n\\nAfter all, brains are part of the body, and bodies are made of cells and many other constituents, some of which are not literally ours, like our unique DNA is. There are many ‘Brain and Body’ research institutes around the world, but no ‘Liver and Body’ institutes. Why is that? It’s because we think the liver is (part) of the body. But why are we so reluctant to consider the brain as just another part of the body? There’s no evidence that the brain is made of a different kind of ‘physical stuff’ from the rest of the body.\\n\\nI propose a shift in focus from neural to cellular processing to highlight the fundamental role of cells in constituting biological self-organising systems such as the human body.\\n\\nThe journey of understanding who we are, scientifically and philosophically, starts traditionally with a thinking guy – yes, it’s usually a guy, a solitary male genius – sorting out the mystery of the Universe from within his ivory tower. Yet, the journey of who we are as living beings starts way before, when a couple of cells start negotiating energetic resources with some other bunch of cells in the depths of a womb.\\n\\nAs a philosopher/frustrated musician/cognitive neuroscientist, I now give academic talks all over the world, and one of my favourite things to do is to say the following line while carefully scanning the audience for their reactions: ‘You have all spent time growing inside another person’s body.’ Most of the time, people’s eyes widen as if some big mystery has just been revealed to them. Some nod their heads, others seem perplexed or in denial. But surely these smart academics know that babies don’t just drop from the sky or pop out from cabbages? As adults, we all know that we have been babies ourselves, and that we have all developed inside another person’s body. Why is this biological and scientific fact so difficult to recognise for our intelligentsia? Why are we so obsessed with minds, with pure self-conscious minds, while forgetting about bodies, and specifically about the other body that carried and fed our own one? Just think about it: long before being these lovely adults with hopes and dreams and failures, drinking coffee, paying taxes, and reading fancy books and articles online, each of us spent some time as a single cell.\\n\\nEven more mind-blowing: all human beings gradually develop from cells to a human body within another human body. Pregnancy is a universal human fact that concerns everyone, not just a few of us. All cells of the human organism originate from a single cell, the zygote, are closely interconnected, mutually influence one another, and operate in synchrony to achieve common goals – maintenance of homeostasis and constant adaptation to changes of the surrounding environment. This means that we arrive into this world not on a solitary rock dropped by some mastermind, but as living biological creatures deeply dependent upon and connected with another living body. And then we need others to take care of us for quite some time before we can find a rock to sit on and think about deep things like the meaning of life or quantum physics.\\n\\nFor that Thinker to contemplate the meaning of life, he has to self-regulate his humble internal bodily states\\n\\nTo understand minds, we need to grasp first how we become minds. We need to start with the cells that compose our humble toes before zooming into the mystery of the brain. Why? Because our cells solve the biggest and most urgent problem of this great and mysterious adventure called life without a brain, and before we had a brain: how to stay alive.\\n\\nHumans are living creatures. Living creatures are self-organising biological systems whose bodies constantly perform the humble yet essential, basic task of keeping track of self-related information-processing to secure survival. In short, this means that your body works for you even when you are asleep or under anaesthesia: your heart keeps beating for you, not for someone else. This also means that all bodily processes have the self at their very core, simply because they obey the universal drive governing all living systems which is: don’t die! Self-preservation is fundamental. But because our body is a living system governed by the basic law of self-preservation, this means that all our experiences are necessarily embodied self-experiences. In perceiving and experiencing the world, we ‘smuggle in’ our own fundamental self-survival goals. This is something we share with cats and worms and viruses. Whether this is also something we share with artificial systems is another story.\\n\\nBodily experiences are thus necessarily connected to biological self-regulation (or homeostasis) and self-preservation. For example, a penguin can survive in very cold temperatures, while humans can’t. Every organism has a set of optimal states it has to maintain in order to stay alive. If you are too cold, or too hot, or you need to go to the loo, or you are hungry and dream of salads, then you can’t think properly and solve complex abstract problems. For that Thinker to be able to contemplate the meaning of life on a rock, first he has to successfully self-regulate his humble internal bodily states. In short, the body is life – it is the sine qua non of human existence. If one is alive, one is experiencing through one’s body, even when asleep, even under anaesthesia. And this very simple idea is crucial for redefining how we understand cognition.\\n\\nHow?\\n\\nLet’s forget for a moment the Thinker, static and isolated on his pedestal, and go back to the growing or developing thinker. How did she get there in the first place? What is this thinker made of? Is she hungry or upset? All these questions may seem silly or irrelevant for the noble question ‘What is cognition?’ but here I suggest that, actually, it’s quite the opposite.\\n\\nTo understand how the neurons work and how we get from neurons to minds, we first need to get back to square one, to understand how we get from cells to selves.\\n\\n')]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "file_path = \"/Users/toshalimohapatra/Documents/Chatbot_Langchain/data/textfile.txt\"\n",
    "loader = TextLoader(file_path)\n",
    "text_documents = loader.load()\n",
    "text_documents[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6ec6ee13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8cd78038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd9ab2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n"
     ]
    }
   ],
   "source": [
    "## Read from web based loader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from bs4.filter import SoupStrainer\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3ebc3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c733702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 8}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 971}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 3549}, page_content='Self-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)')]\n",
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  \n",
    "    chunk_overlap=200,  \n",
    "    add_start_index=True,  \n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(all_splits[:5])\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70262d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.18', 'creator': 'LaTeX with hyperref package', 'creationdate': '2018-06-08T19:14:34+00:00', 'author': '', 'keywords': '', 'moddate': '2025-09-23T22:25:51+05:30', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017) kpathsea version 6.2.3', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/toshalimohapatra/Documents/Chatbot_Langchain/data/GPT_1.pdf', 'total_pages': 12, 'page': 0, 'page_label': '1'}, page_content='Improving Language Understanding\\nby Generative Pre-Training\\nAlec Radford\\nOpenAI\\nalec@openai.com\\nKarthik Narasimhan\\nOpenAI\\nkarthikn@openai.com\\nTim Salimans\\nOpenAI\\ntim@openai.com\\nIlya Sutskever\\nOpenAI\\nilyasu@openai.com\\nAbstract\\nNatural language understanding comprises a wide range of diverse tasks such\\nas textual entailment, question answering, semantic similarity assessment, and\\ndocument classiﬁcation. Although large unlabeled text corpora are abundant,\\nlabeled data for learning these speciﬁc tasks is scarce, making it challenging for\\ndiscriminatively trained models to perform adequately. We demonstrate that large\\ngains on these tasks can be realized by generative pre-training of a language model\\non a diverse corpus of unlabeled text, followed bydiscriminative ﬁne-tuning on each\\nspeciﬁc task. In contrast to previous approaches, we make use of task-aware input\\ntransformations during ﬁne-tuning to achieve effective transfer while requiring\\nminimal changes to the model architecture. We demonstrate the effectiveness of\\nour approach on a wide range of benchmarks for natural language understanding.\\nOur general task-agnostic model outperforms discriminatively trained models that\\nuse architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the\\nstate of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute\\nimprovements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on\\nquestion answering (RACE), and 1.5% on textual entailment (MultiNLI).\\n1 Introduction\\nThe ability to learn effectively from raw text is crucial to alleviating the dependence on supervised\\nlearning in natural language processing (NLP). Most deep learning methods require substantial\\namounts of manually labeled data, which restricts their applicability in many domains that suffer\\nfrom a dearth of annotated resources [61]. In these situations, models that can leverage linguistic\\ninformation from unlabeled data provide a valuable alternative to gathering more annotation, which\\ncan be time-consuming and expensive. Further, even in cases where considerable supervision\\nis available, learning good representations in an unsupervised fashion can provide a signiﬁcant\\nperformance boost. The most compelling evidence for this so far has been the extensive use of pre-\\ntrained word embeddings [10, 39, 42] to improve performance on a range of NLP tasks [8, 11, 26, 45].\\nLeveraging more than word-level information from unlabeled text, however, is challenging for two\\nmain reasons. First, it is unclear what type of optimization objectives are most effective at learning\\ntext representations that are useful for transfer. Recent research has looked at various objectives\\nsuch as language modeling [44], machine translation [38], and discourse coherence [22], with each\\nmethod outperforming the others on different tasks. 1 Second, there is no consensus on the most\\neffective way to transfer these learned representations to the target task. Existing techniques involve\\na combination of making task-speciﬁc changes to the model architecture [ 43, 44], using intricate\\nlearning schemes [21] and adding auxiliary learning objectives [50]. These uncertainties have made\\nit difﬁcult to develop effective semi-supervised learning approaches for language processing.\\n1https://gluebenchmark.com/leaderboard\\nPreprint. Work in progress.')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "file_path = \"/Users/toshalimohapatra/Documents/Chatbot_Langchain/data/GPT_1.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "docs = loader.load()\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b3b6c",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eba0af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"qwen2.5-coder:0.5b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "315e8363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is the framework for building context-aware reasoning applications\n"
     ]
    }
   ],
   "source": [
    "# Create a vector store with a sample text\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    [text],\n",
    "    embedding=embeddings,\n",
    ")\n",
    "\n",
    "# Use the vectorstore as a retriever\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Retrieve the most similar text\n",
    "retrieved_documents = retriever.invoke(\"What is LangChain?\")\n",
    "\n",
    "# Show the retrieved document's content\n",
    "print(retrieved_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c6fc443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.009889353, 0.011473607, -0.0017168578, -0.018002266, 0.0035788615, -0.0030870365, 0.0033981635, 0\n"
     ]
    }
   ],
   "source": [
    "single_vector = embeddings.embed_query(text)\n",
    "print(str(single_vector)[:100])  # Show the first 100 characters of the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "109a61c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.009889353, 0.011473607, -0.0017168578, -0.018002266, 0.0035788615, -0.0030870365, 0.0033981635, 0\n",
      "[-0.0021199523, -0.0019641852, -0.00074170635, -0.01886839, 0.0031963116, -0.007960364, 0.042872794,\n"
     ]
    }
   ],
   "source": [
    "text2 = (\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs\"\n",
    ")\n",
    "two_vectors = embeddings.embed_documents([text, text2])\n",
    "for vector in two_vectors:\n",
    "    print(str(vector)[:100])  # Show the first 100 characters of the vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fa49b",
   "metadata": {},
   "source": [
    "### Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a6fc86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ChromaDB implementation \n",
    "from langchain_community.vectorstores import Chroma\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=docs[:10],\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b7ce315b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Improving Language Understanding\\nby Generative Pre-Training\\nAlec Radford\\nOpenAI\\nalec@openai.com\\nKarthik Narasimhan\\nOpenAI\\nkarthikn@openai.com\\nTim Salimans\\nOpenAI\\ntim@openai.com\\nIlya Sutskever\\nOpenAI\\nilyasu@openai.com\\nAbstract\\nNatural language understanding comprises a wide range of diverse tasks such\\nas textual entailment, question answering, semantic similarity assessment, and\\ndocument classiﬁcation. Although large unlabeled text corpora are abundant,\\nlabeled data for learning these speciﬁc tasks is scarce, making it challenging for\\ndiscriminatively trained models to perform adequately. We demonstrate that large\\ngains on these tasks can be realized by generative pre-training of a language model\\non a diverse corpus of unlabeled text, followed bydiscriminative ﬁne-tuning on each\\nspeciﬁc task. In contrast to previous approaches, we make use of task-aware input\\ntransformations during ﬁne-tuning to achieve effective transfer while requiring\\nminimal changes to the model architecture. We demonstrate the effectiveness of\\nour approach on a wide range of benchmarks for natural language understanding.\\nOur general task-agnostic model outperforms discriminatively trained models that\\nuse architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the\\nstate of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute\\nimprovements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on\\nquestion answering (RACE), and 1.5% on textual entailment (MultiNLI).\\n1 Introduction\\nThe ability to learn effectively from raw text is crucial to alleviating the dependence on supervised\\nlearning in natural language processing (NLP). Most deep learning methods require substantial\\namounts of manually labeled data, which restricts their applicability in many domains that suffer\\nfrom a dearth of annotated resources [61]. In these situations, models that can leverage linguistic\\ninformation from unlabeled data provide a valuable alternative to gathering more annotation, which\\ncan be time-consuming and expensive. Further, even in cases where considerable supervision\\nis available, learning good representations in an unsupervised fashion can provide a signiﬁcant\\nperformance boost. The most compelling evidence for this so far has been the extensive use of pre-\\ntrained word embeddings [10, 39, 42] to improve performance on a range of NLP tasks [8, 11, 26, 45].\\nLeveraging more than word-level information from unlabeled text, however, is challenging for two\\nmain reasons. First, it is unclear what type of optimization objectives are most effective at learning\\ntext representations that are useful for transfer. Recent research has looked at various objectives\\nsuch as language modeling [44], machine translation [38], and discourse coherence [22], with each\\nmethod outperforming the others on different tasks. 1 Second, there is no consensus on the most\\neffective way to transfer these learned representations to the target task. Existing techniques involve\\na combination of making task-speciﬁc changes to the model architecture [ 43, 44], using intricate\\nlearning schemes [21] and adding auxiliary learning objectives [50]. These uncertainties have made\\nit difﬁcult to develop effective semi-supervised learning approaches for language processing.\\n1https://gluebenchmark.com/leaderboard\\nPreprint. Work in progress.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Where was GLUE benchmark used?\"\n",
    "result = vector_store.similarity_search(query, k=2)\n",
    "result[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "788d2871",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAISS Implementation\n",
    "from langchain_community.vectorstores import FAISS  \n",
    "faiss_vector_store = FAISS.from_documents(\n",
    "    documents=docs[:10],\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "22a5edb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Improving Language Understanding\\nby Generative Pre-Training\\nAlec Radford\\nOpenAI\\nalec@openai.com\\nKarthik Narasimhan\\nOpenAI\\nkarthikn@openai.com\\nTim Salimans\\nOpenAI\\ntim@openai.com\\nIlya Sutskever\\nOpenAI\\nilyasu@openai.com\\nAbstract\\nNatural language understanding comprises a wide range of diverse tasks such\\nas textual entailment, question answering, semantic similarity assessment, and\\ndocument classiﬁcation. Although large unlabeled text corpora are abundant,\\nlabeled data for learning these speciﬁc tasks is scarce, making it challenging for\\ndiscriminatively trained models to perform adequately. We demonstrate that large\\ngains on these tasks can be realized by generative pre-training of a language model\\non a diverse corpus of unlabeled text, followed bydiscriminative ﬁne-tuning on each\\nspeciﬁc task. In contrast to previous approaches, we make use of task-aware input\\ntransformations during ﬁne-tuning to achieve effective transfer while requiring\\nminimal changes to the model architecture. We demonstrate the effectiveness of\\nour approach on a wide range of benchmarks for natural language understanding.\\nOur general task-agnostic model outperforms discriminatively trained models that\\nuse architectures speciﬁcally crafted for each task, signiﬁcantly improving upon the\\nstate of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute\\nimprovements of 8.9% on commonsense reasoning (Stories Cloze Test), 5.7% on\\nquestion answering (RACE), and 1.5% on textual entailment (MultiNLI).\\n1 Introduction\\nThe ability to learn effectively from raw text is crucial to alleviating the dependence on supervised\\nlearning in natural language processing (NLP). Most deep learning methods require substantial\\namounts of manually labeled data, which restricts their applicability in many domains that suffer\\nfrom a dearth of annotated resources [61]. In these situations, models that can leverage linguistic\\ninformation from unlabeled data provide a valuable alternative to gathering more annotation, which\\ncan be time-consuming and expensive. Further, even in cases where considerable supervision\\nis available, learning good representations in an unsupervised fashion can provide a signiﬁcant\\nperformance boost. The most compelling evidence for this so far has been the extensive use of pre-\\ntrained word embeddings [10, 39, 42] to improve performance on a range of NLP tasks [8, 11, 26, 45].\\nLeveraging more than word-level information from unlabeled text, however, is challenging for two\\nmain reasons. First, it is unclear what type of optimization objectives are most effective at learning\\ntext representations that are useful for transfer. Recent research has looked at various objectives\\nsuch as language modeling [44], machine translation [38], and discourse coherence [22], with each\\nmethod outperforming the others on different tasks. 1 Second, there is no consensus on the most\\neffective way to transfer these learned representations to the target task. Existing techniques involve\\na combination of making task-speciﬁc changes to the model architecture [ 43, 44], using intricate\\nlearning schemes [21] and adding auxiliary learning objectives [50]. These uncertainties have made\\nit difﬁcult to develop effective semi-supervised learning approaches for language processing.\\n1https://gluebenchmark.com/leaderboard\\nPreprint. Work in progress.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Where was GLUE benchmark used?\"\n",
    "result = vector_store.similarity_search(query, k=2)\n",
    "result[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714dfe2",
   "metadata": {},
   "source": [
    "### Chains and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b9607800",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chat prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following question based on the context provided. Think logically step by steo before providing a detailed answer. Be respectful, detailed, and professional in your response.\n",
    "<context>{context}</context>\n",
    "Question: {input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "653b18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "llm = Ollama(model=\"qwen2.5-coder:0.5b\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,      # whatever PromptTemplate you defined\n",
    ")\n",
    "\n",
    "retriever = faiss_vector_store.as_retriever()\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain=document_chain,\n",
    ")\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"Where was GLUE benchmark used?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6046c8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GLUE benchmark was used to evaluate the performance of the model in 9 out of the 12 datasets we evaluated on.'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8a1b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
